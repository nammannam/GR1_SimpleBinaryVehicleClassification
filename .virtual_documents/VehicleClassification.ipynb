!pip list






import tensorflow as tf


gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)


import tensorflow as tf
print("TensorFlow CUDA built with: ", tf.sysconfig.get_build_info()['cuda_version'])
print("GPU: ", tf.config.list_physical_devices('GPU'))









from datasets import load_dataset, DatasetDict


dataset_url = 'uoft-cs/cifar10'
my_dataset = load_dataset(dataset_url)



# my_dataset['train'][10]
print(my_dataset['train'].features)


# Lọc chỉ giữ label 0 và 1 từ tập 'train'
filtered_train = my_dataset['train'].filter(lambda example: example['label'] in [0, 1])

# Tách filtered_train thành train + validation (VD: 70% train, 30% validation)
split = filtered_train.train_test_split(test_size=0.3, seed=42)

# Lọc test cũng chỉ giữ label 0 và 1
filtered_test = my_dataset['test'].filter(lambda example: example['label'] in [0, 1])

# Tạo lại DatasetDict hoàn chỉnh
binary_dataset = DatasetDict({
    'train': split['train'],
    'validation': split['test'],
    'test': filtered_test
})





#Test binary dataset

print(binary_dataset['train'].shape)
print(binary_dataset['validation'].shape)
print(binary_dataset['test'].shape)

# Kiểm tra các label có trong tập train
print("Train labels:", set(binary_dataset['train']['label']))

# Kiểm tra tập validation và test
print("Validation labels:", set(binary_dataset['validation']['label']))
print("Test labels:", set(binary_dataset['test']['label']))


import matplotlib.pyplot as plt
from PIL import Image

# Lấy 1 mẫu đầu tiên trong tập train
sample = binary_dataset['train'][10]
image = sample['img']
label = sample['label']

# image = image.resize((320, 320), resample=Image.BILINEAR)

# Hiển thị ảnh
plt.imshow(image)
plt.title(f"Label: {label}")
plt.axis('off')
plt.show()



import numpy as np

image_np = np.array(image)

image_np.shape





import numpy as np
import tensorflow as tf

# Hàm không cần trả về dict nữa nếu dùng trong generator
def convert_to_tf_dataset(hf_dataset, batch_size=32, shuffle=False):
    def gen():
        for example in hf_dataset:
            image = np.array(example['img']).astype(np.float32) / 255.0
            label = example['label']
            yield image, label  #Trả về tuple (img, label)

    # Định nghĩa cấu trúc output đúng
    ds = tf.data.Dataset.from_generator(
        gen,
        output_signature=(
            tf.TensorSpec(shape=(32, 32, 3), dtype=tf.float32),
            tf.TensorSpec(shape=(), dtype=tf.int64)
        )
    )

    if shuffle:
        ds = ds.shuffle(buffer_size=1000)
    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)



train_ds = convert_to_tf_dataset(binary_dataset['train'], batch_size=32, shuffle=True)
val_ds   = convert_to_tf_dataset(binary_dataset['validation'], batch_size=32)
test_ds  = convert_to_tf_dataset(binary_dataset['test'], batch_size=32)






print("Train: ",train_ds)
print("Validation: ",val_ds)
print("Test: ",test_ds)



train_iterator = train_ds.as_numpy_iterator()


train_batch = train_iterator.next()


train_batch[0].shape








from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization


model = Sequential()


model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.8))
model.add(Dense(1, activation='sigmoid'))  # Phân loại nhị phân


model.compile('adam', loss = tf.losses.BinaryCrossentropy(), metrics = ['accuracy'])


model.summary()





logdir = 'logs'


tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)


hist = model.fit(train_ds, epochs = 100, validation_data = val_ds, callbacks = [tensorboard_callback])





fig = plt.figure()
plt.plot(hist.history['loss'], color = 'teal', label = 'loss')
plt.plot(hist.history['val_loss'], color = 'orange', label = 'val_loss')
fig.suptitle('Loss', fontsize = 20)
plt.legend(loc = 'upper left')
plt.show


fig = plt.figure()
plt.plot(hist.history['accuracy'], color = 'teal', label = 'accuracy')
plt.plot(hist.history['val_accuracy'], color = 'orange', label = 'val_accuracy')
fig.suptitle('Accuracy', fontsize = 20)
plt.legend(loc = 'upper left')
plt.show





import os

model.save(os.path.join('modelSave','BinaryVehicleClassification.h5'))






from tensorflow.keras.models import load_model
import os

loaded_model = load_model(os.path.join('modelSave','BinaryVehicleClassification.h5'))



import numpy as np
import matplotlib.pyplot as plt
import time

# Lấy 1 batch từ test_ds
for images, labels in test_ds.take(1):
    for i in range(10):  # Chỉ lấy 5 ảnh đầu
        img = tf.expand_dims(images[i], axis=0)  # Thêm batch dimension: (1, 32, 32, 3)

        start_t = time.perf_counter()
        pred = loaded_model.predict(img, verbose=0)
        end_t = time.perf_counter()

        infer_t = (end_t - start_t) * 1000  # Thời gian tính bằng mili giây
        infer_t = round(infer_t, 2)  # Làm tròn 2 chữ số sau dấu chấm

        plt.figure(figsize=(2, 2))
        plt.imshow(images[i].numpy())
        plt.title(f"Predicted: {pred[0]} | Truth: {labels[i].numpy()} | Time: {infer_t} ms")
        plt.axis('off')
        plt.show()


import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
img = cv2.imread('.\\data_to_newTesting\\VehicleClassification\\car.jpg')
plt.imshow(cv2.cvtColor(img , cv2.COLOR_BGR2RGB))
plt.show()


resize = tf.image.resize(img, (32,32))
plt.imshow(resize.numpy().astype(int))
plt.show()


resize_np = resize.numpy().astype(int)
resize_np.shape


predict = loaded_model.predict(np.expand_dims(resize/250, 0))

if predict > 0.5:
    print("Car: ", predict)
else:
    print("Airplane: ", predict)



